{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- CONV2D FORWARD PASS --- \n",
    "\n",
    "def conv2d_forward(input_data, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Performs a 2D convolution forward pass (single channel input).\n",
    "    Note: We are implementing the loops manually for low-level understanding.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. SETUP SHAPES\n",
    "    # Input Data: (H, W) - Height, Width (e.g., 5x5 image)\n",
    "    (i_h, i_w) = input_data.shape \n",
    "    # Kernel: (F_h, F_w) - Filter Height, Filter Width (e.g., 3x3 filter)\n",
    "    (f_h, f_w) = kernel.shape\n",
    "    \n",
    "    # Calculate Output Dimensions\n",
    "    # Formula for output size (no padding, stride=1): O = (I - F) + 1\n",
    "    o_h = int((i_h - f_h) / stride) + 1\n",
    "    o_w = int((i_w - f_w) / stride) + 1\n",
    "    \n",
    "    # Initialize the output Feature Map\n",
    "    output = np.zeros((o_h, o_w))\n",
    "    \n",
    "    # 2. THE SLIDING WINDOW (The Core of CNNs)\n",
    "    # Slide the filter vertically (i) and horizontally (j)\n",
    "    for i in range(o_h):\n",
    "        for j in range(o_w):\n",
    "            \n",
    "            # Define the current slice (window) of the input data\n",
    "            # Use the stride to skip pixels\n",
    "            i_start = i * stride\n",
    "            j_start = j * stride\n",
    "            \n",
    "            # Get the slice matching the kernel size\n",
    "            input_slice = input_data[i_start : i_start + f_h, \n",
    "                                     j_start : j_start + f_w]\n",
    "            \n",
    "            # 3. THE DOT PRODUCT (Multiplication and Summation)\n",
    "            # The convolution operation: Element-wise multiply the slice and the kernel, then sum\n",
    "            feature_value = np.sum(input_slice * kernel)\n",
    "            \n",
    "            # Store the single result in the output feature map\n",
    "            output[i, j] = feature_value\n",
    "            \n",
    "    return output\n",
    "\n",
    "# --- DEMO ---\n",
    "# Simple 5x5 image (H, W)\n",
    "X = np.array([\n",
    "    [1, 1, 1, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "# Edge detection filter (3x3 kernel)\n",
    "K = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "# Run the convolution\n",
    "# 5x5 image with 3x3 kernel (stride 1, no padding) should yield a 3x3 output.\n",
    "output_feature_map = conv2d_forward(X, K)\n",
    "\n",
    "print(\"Input Image (X):\\n\", X)\n",
    "print(\"\\nFilter (K):\\n\", K)\n",
    "print(\"\\nOutput Feature Map (5-3+1 = 3x3):\\n\", output_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAXPOOL FORWARD PASS ---\n",
    "def maxpool_forward(feature_map, pool_size=2, stride=2):\n",
    "    \"\"\"\n",
    "    Performs Max Pooling (downsampling).\n",
    "    Finds the maximum value within a pool_size window.\n",
    "    \"\"\"\n",
    "    (i_h, i_w) = feature_map.shape\n",
    "    \n",
    "    # Calculate Output Dimensions\n",
    "    # O = I / S (for size=stride)\n",
    "    o_h = int(i_h / stride)\n",
    "    o_w = int(i_w / stride)\n",
    "    \n",
    "    output = np.zeros((o_h, o_w))\n",
    "    \n",
    "    for i in range(o_h):\n",
    "        for j in range(o_w):\n",
    "            \n",
    "            # Define the current pooling window\n",
    "            i_start = i * stride\n",
    "            j_start = j * stride\n",
    "            \n",
    "            # Get the slice matching the pool size\n",
    "            input_slice = feature_map[i_start : i_start + pool_size,\n",
    "                                      j_start : j_start + pool_size]\n",
    "            \n",
    "            # The Max Pool operation: Find the single largest value\n",
    "            output[i, j] = np.max(input_slice)\n",
    "            \n",
    "    return output\n",
    "\n",
    "# --- DEMO ---\n",
    "# Use the output from the convolution above (3x3)\n",
    "# We will pad it to 4x4 for a clean 2x2 maxpool (usually images are padded)\n",
    "padded_map = np.pad(output_feature_map, ((0,1), (0,1)), 'constant') # Simple padding to make 4x4\n",
    "pooled_output = maxpool_forward(padded_map, pool_size=2, stride=2)\n",
    "\n",
    "print(\"\\nPadded Feature Map (4x4):\\n\", padded_map)\n",
    "print(\"\\nMax Pooled Output (2x2):\\n\", pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# --- CONV2D WITH PyTorch ---\n",
    "def conv2d_pytorch_forward(input_data, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    PyTorch version - No manual loops needed!\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    # Add batch and channel dimensions: (batch_size, channels, height, width)\n",
    "    # Our input is (H,W) -> needs to be (1, 1, H, W) for PyTorch conv2d\n",
    "    input_tensor = torch.from_numpy(input_data).float().unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Kernel also needs same dimensions: (out_channels, in_channels, H, W)\n",
    "    kernel_tensor = torch.from_numpy(kernel).float().unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    print(f\"Input shape: {input_tensor.shape}\")\n",
    "    print(f\"Kernel shape: {kernel_tensor.shape}\")\n",
    "    \n",
    "    # METHOD 1: Using torch.nn.functional.conv2d (most common)\n",
    "    output = F.conv2d(input_tensor, kernel_tensor, \n",
    "                     stride=stride, padding=padding)\n",
    "    \n",
    "    # Remove batch and channel dimensions for comparison\n",
    "    output = output.squeeze()\n",
    "    \n",
    "    return output.numpy()\n",
    "\n",
    "# --- DEMO ---\n",
    "print(\"=== PyTorch CONVOLUTION ===\")\n",
    "X = np.array([\n",
    "    [1, 1, 1, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "K = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "# One line of code does all the work we manually coded!\n",
    "output_pytorch = conv2d_pytorch_forward(X, K)\n",
    "print(\"PyTorch Output:\\n\", output_pytorch)\n",
    "\n",
    "# --- EVEN SIMPLER: Using nn.Conv2d layer ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Using nn.Conv2d Layer (Even Easier!)\")\n",
    "\n",
    "# Create a convolution layer\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, \n",
    "                      stride=1, padding=0, bias=False)\n",
    "\n",
    "# Set the weights to our custom kernel\n",
    "with torch.no_grad():\n",
    "    conv_layer.weight.data = torch.from_numpy(K).float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Forward pass\n",
    "input_tensor = torch.from_numpy(X).float().unsqueeze(0).unsqueeze(0)\n",
    "output_layer = conv_layer(input_tensor)\n",
    "\n",
    "print(\"nn.Conv2d Output:\\n\", output_layer.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAX POOLING WITH PyTorch ---\n",
    "def maxpool_pytorch_forward(feature_map, pool_size=2, stride=2):\n",
    "    \"\"\"\n",
    "    PyTorch max pooling - super simple!\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to tensor and add dimensions\n",
    "    input_tensor = torch.from_numpy(feature_map).float().unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    print(f\"Pool input shape: {input_tensor.shape}\")\n",
    "    \n",
    "    # METHOD 1: Using torch.nn.functional.max_pool2d\n",
    "    output = F.max_pool2d(input_tensor, kernel_size=pool_size, \n",
    "                         stride=stride)\n",
    "    \n",
    "    # Remove extra dimensions\n",
    "    output = output.squeeze()\n",
    "    \n",
    "    return output.numpy()\n",
    "\n",
    "# --- DEMO ---\n",
    "print(\"\\n=== PyTorch MAX POOLING ===\")\n",
    "\n",
    "# Use the convolution output and pad it\n",
    "padded_map = np.pad(output_pytorch, ((0,1), (0,1)), 'constant')\n",
    "\n",
    "# One line does all the max pooling!\n",
    "pooled_pytorch = maxpool_pytorch_forward(padded_map)\n",
    "print(\"Padded Input:\\n\", padded_map)\n",
    "print(\"PyTorch Max Pool Output:\\n\", pooled_pytorch)\n",
    "\n",
    "# --- USING nn.MaxPool2d LAYER ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Using nn.MaxPool2d Layer\")\n",
    "\n",
    "# Create max pool layer\n",
    "maxpool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# Forward pass\n",
    "input_tensor = torch.from_numpy(padded_map).float().unsqueeze(0).unsqueeze(0)\n",
    "pooled_layer = maxpool_layer(input_tensor)\n",
    "\n",
    "print(\"nn.MaxPool2d Output:\\n\", pooled_layer.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
